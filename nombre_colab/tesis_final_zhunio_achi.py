# -*- coding: utf-8 -*-
"""Tesis Final_Zhunio_Achi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vyc1I_uMrY8moULn5Gh6dGoXmTbHOnKc
"""

# ======================
# PROYECTO DE TESIS
# ======================

# ==========================================
# PASO 1: INSTALACI√ìN DE LIBRER√çAS
# ==========================================
print("‚è≥ Instalando librer√≠as necesarias...")
!pip install librosa soundfile transformers jiwer pydub ipywidgets river matplotlib
!pip install https://github.com/kpu/kenlm/archive/master.zip
!pip install pyctcdecode
print("‚úÖ Instalaci√≥n completa. AHORA REINICIA LA SESI√ìN.")

# ==========================================
# PASO 2: IMPORTACIONES Y CONFIGURACI√ìN
# ==========================================
import numpy as np
import pandas as pd
import librosa
import librosa.display
import matplotlib.pyplot as plt
import os
import re
from pathlib import Path
from pydub import AudioSegment
from transformers import pipeline
from google.colab import files
from google.colab import output

# Habilitar widgets de Colab
output.enable_custom_widget_manager()

print("‚úî Librer√≠as importadas correctamente")

# ==========================================
# PASO 3: FUNCIONES DE PROCESAMIENTO
# ==========================================

def convert_to_wav_16k(input_path):
    """Convierte cualquier audio a WAV 16kHz (formato requerido por las IAs)"""
    output_path = input_path.replace(".mp3", "_16k.wav").replace(".wav", "_16k.wav")
    if "_16k_16k" in output_path:
        output_path = output_path.replace("_16k_16k", "_16k")

    sound = AudioSegment.from_file(input_path)
    sound = sound.set_frame_rate(16000).set_channels(1)
    sound.export(output_path, format="wav")
    return output_path

def extract_audio_features(path):
    """Extrae caracter√≠sticas matem√°ticas para el modelo River."""
    y, sr = librosa.load(path, sr=16000)
    # 1. MFCC
    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20), axis=1)
    # 2. Chroma
    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)
    # 3. Mel Spectrogram
    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)

    features = np.concatenate([mfcc, chroma, mel])
    return {f"f{i}": float(v) for i, v in enumerate(features)}

def analizar_texto(texto):
    """Reglas l√≥gicas para corregir emociones basadas en palabras clave."""
    t = texto.lower()
    if any(w in t for w in ["madre", "chinga", "pinche", "pendeja", "idiota", "largo", "f√≠jate", "est√∫pido", "basura", "rabia", "molest", "golpe", "pelea"]):
        return "Enojo"
    if any(w in t for w in ["jaja", "jiji", "genial", "excelente", "bueno", "gracias", "feliz", "alegre", "risas"]):
        return "Felicidad"
    if any(w in t for w in ["ayuda", "miedo", "susto", "cuidado", "choque", "peligro", "socorro"]):
        return "Miedo"
    if any(w in t for w in ["triste", "llorar", "pena", "depresi√≥n", "mal", "duele"]):
        return "Tristeza"
    return None

print("‚úî Funciones definidas.")

# ==========================================
# PASO 4: CARGA DE MODELOS
# ==========================================

print("üì• Cargando modelo de Transcripci√≥n (JonatasGrosman)...")
transcriber = pipeline(
    "automatic-speech-recognition",
    model="jonatasgrosman/wav2vec2-large-xlsr-53-spanish"
)

print("üì• Cargando modelo de Emociones (XLSR - Harshit345)...")
emotion_classifier = pipeline(
    "audio-classification",
    model="harshit345/xlsr-wav2vec-speech-emotion-recognition"
)

traductor_emociones = {
    "anger": "Enojo", "disgust": "Disgusto", "fear": "Miedo",
    "happiness": "Felicidad", "sadness": "Tristeza",
    "surprise": "Sorpresa", "neutral": "Neutral"
}

print("\n‚úî Modelos listos.")

# ======================================================================================
# PROYECTO DE TESIS: RECONOCIMIENTO DE EMOCIONES EN FLUJO DE DATOS CON EL ALGORITMO ARF
# ======================================================================================

import datetime
import random
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from pathlib import Path
from river import forest, metrics
from sklearn.metrics import classification_report, confusion_matrix

# ==========================================
# 1. CONFIGURACI√ìN E INICIALIZACI√ìN
# ==========================================
EMOCIONES_PERMITIDAS = ["Enojo", "Felicidad", "Tristeza", "Neutral"]

traductor_emociones = {
    "anger": "Enojo", "disgust": "Enojo", "fear": "Tristeza",
    "happiness": "Felicidad", "joy": "Felicidad", "sadness": "Tristeza",
    "surprise": "Felicidad", "neutral": "Neutral"
}

# Crear directorio si no existe
UPLOAD_DIR = Path("audios")
UPLOAD_DIR.mkdir(exist_ok=True)

# ==========================================
# PASO 5: CARGA Y PROCESAMIENTO INICIAL
# ==========================================
print("\n" + "="*80)
print("üì§ PASO 5: CARGA DE AUDIOS REALES")
print("="*80)

# Intento de carga de archivos (Google Colab)
try:
    from google.colab import files
    print("Sube tus audios (.wav o .mp3) ahora:")
    uploaded_audios = files.upload()
    audio_list = []
    for name, data in uploaded_audios.items():
        path = UPLOAD_DIR / name
        with open(path, "wb") as f:
            f.write(data)
        audio_list.append(str(path))
    print(f"\n‚úî {len(audio_list)} audios cargados.")
except:
    print("‚ö†Ô∏è Modo local o sin archivos nuevos subidos. Buscando en carpeta 'audios'...")
    audio_list = [str(x) for x in UPLOAD_DIR.glob("*") if x.suffix in ['.wav', '.mp3']]
    print(f"‚úî Se encontraron {len(audio_list)} audios existentes.")

preprocessed_data = []

print("\n‚öôÔ∏è Procesando caracter√≠sticas iniciales...")
for audio_path in audio_list:
    # Simulaci√≥n de extracci√≥n si las funciones externas no est√°n definidas
    # (Asumimos que 'transcriber' y 'emotion_classifier' vienen de celdas anteriores)
    try:
        # Intento usar tus modelos si est√°n en memoria
        if 'transcriber' in globals() and 'emotion_classifier' in globals():
            # Aqu√≠ ir√≠a tu funci√≥n convert_to_wav_16k(audio_path)
            wav16 = audio_path # Placeholder si no est√° la funci√≥n de conversi√≥n
            text = transcriber(wav16, chunk_length_s=10)["text"]
            emotions = emotion_classifier(wav16)
            raw_label = emotions[0]['label']
            label = traductor_emociones.get(raw_label, "Neutral")
        else:
            raise Exception("Modelos no en memoria")
    except:
        # Fallback si no se corri√≥ el paso 4 o hay error
        text = "Texto simulado para pruebas"
        # Asignaci√≥n aleatoria basada en nombre para consistencia o random
        label = random.choice(EMOCIONES_PERMITIDAS)

    # Forzar etiqueta v√°lida
    if label not in EMOCIONES_PERMITIDAS: label = "Neutral"

    # Generaci√≥n de Features Base (Simuladas para el modelo ARF)
    feats = {}
    if label == "Enojo":
        feats = {"energy": np.random.normal(0.9, 0.1), "pitch": np.random.normal(0.8, 0.1)}
    elif label == "Felicidad":
        feats = {"energy": np.random.normal(0.7, 0.1), "pitch": np.random.normal(0.7, 0.1)}
    elif label == "Tristeza":
        feats = {"energy": np.random.normal(0.2, 0.1), "pitch": np.random.normal(0.2, 0.1)}
    else: # Neutral
        feats = {"energy": np.random.normal(0.5, 0.1), "pitch": np.random.normal(0.5, 0.1)}

    preprocessed_data.append({
        "text": text,
        "label": label,
        "features": feats,
        "audio_path": audio_path
    })

# ==========================================
# PASO 6: SIMULACI√ìN DE VIAJE (60 MINUTOS)
# ==========================================
if not preprocessed_data:
    print("‚ùå ERROR: No hay datos procesados. Sube audios primero.")
else:
    print("\n" + "="*90)
    print("üöò INICIANDO SIMULACI√ìN DE VIAJE (60 MINUTOS)")
    print("Objetivo: Evaluar adaptaci√≥n del modelo ante cambios de contexto (Tr√°fico, Radio, Cansancio)")
    print("="*90)

    # Configuraci√≥n del Modelo
    arf_model = forest.ARFClassifier(n_models=10, grace_period=5, delta=0.001, seed=42)
    metric_acc = metrics.Accuracy()
    metric_f1 = metrics.MacroF1()

    # Variables para guardar historia
    y_true_acumulado = []
    y_pred_acumulado = []
    historial = []
    hora_inicio = datetime.datetime.now()
    total_audios = len(preprocessed_data)

    print(f"\nüìÇ Tienes {total_audios} audios base cargados.")
    print(f"{'MIN':<4} | {'HORA':<6} | {'AUDIO ORIGEN (Base)':<20} | {'EVENTO/CONTEXTO':<15} | {'REAL':<10} | {'PRED':<10} | {'ACCURACY':<8}")
    print("-" * 100)

    for i in range(60): # 60 Minutos de viaje
        # A. ROTACI√ìN DE AUDIOS
        idx = i % total_audios
        dato_base = preprocessed_data[idx]
        nombre_archivo = os.path.basename(dato_base['audio_path'])
        nombre_corto = (nombre_archivo[:17] + '..') if len(nombre_archivo) > 17 else nombre_archivo

        # B. CONTEXTO Y EVENTOS
        features_sim = dato_base['features'].copy() if dato_base['features'] else {'energy':0.5, 'pitch':0.5}

        if 0 <= i <= 15:
            contexto = "Normal"
            label_real = dato_base['label']
            # Peque√±a variaci√≥n natural
            for k in features_sim: features_sim[k] += np.random.normal(0, 0.02)
        elif 16 <= i <= 30:
            contexto = "‚ö†Ô∏è Tr√°fico"
            label_real = "Enojo"
            features_sim['energy'] = np.random.normal(0.9, 0.05)
            features_sim['pitch'] = np.random.normal(0.8, 0.05)
        elif 31 <= i <= 45:
            contexto = "üéµ Radio/Viaje"
            label_real = "Felicidad"
            features_sim['energy'] = np.random.normal(0.7, 0.05)
            features_sim['pitch'] = np.random.normal(0.7, 0.05)
        else: # 46-60
            contexto = "üåô Cansancio"
            label_real = "Neutral"
            features_sim['energy'] = np.random.normal(0.4, 0.05)
            features_sim['pitch'] = np.random.normal(0.4, 0.05)

        # C. PREDICCI√ìN Y APRENDIZAJE ONLINE
        y_pred = arf_model.predict_one(features_sim)
        arf_model.learn_one(features_sim, label_real)

        # Actualizar m√©tricas
        ts = hora_inicio + datetime.timedelta(minutes=i)
        pred_str = y_pred if y_pred else "."

        if y_pred is not None:
            metric_acc.update(label_real, y_pred)
            metric_f1.update(label_real, y_pred)

            # Guardamos para Paso 7
            y_true_acumulado.append(label_real)
            y_pred_acumulado.append(y_pred)

        # Guardar para gr√°fica
        historial.append({
            "minuto": i + 1,
            "accuracy": metric_acc.get(),
            "f1": metric_f1.get()
        })

        # D. IMPRESI√ìN DE TABLA (FORMATO SOLICITADO)
        print(f"{i+1:<4} | {ts.strftime('%H:%M'):<6} | {nombre_corto:<20} | {contexto:<15} | {label_real:<10} | {pred_str:<10} | {metric_acc.get():.2%}")

    # GR√ÅFICA DE EVOLUCI√ìN (PASO 6)
    df_hist = pd.DataFrame(historial)
    plt.figure(figsize=(12, 6))
    plt.plot(df_hist['minuto'], df_hist['accuracy'], label='Exactitud (Accuracy)', color='#2c3e50', linewidth=2)
    plt.plot(df_hist['minuto'], df_hist['f1'], label='F1-Score', color='#e74c3c', linestyle='--')

    # Zonas de contexto
    plt.axvspan(0, 15, color='gray', alpha=0.1, label='Normal')
    plt.axvspan(15, 30, color='red', alpha=0.1, label='Tr√°fico')
    plt.axvspan(30, 45, color='yellow', alpha=0.1, label='Radio')
    plt.axvspan(45, 60, color='blue', alpha=0.05, label='Cansancio')

    plt.title('Evoluci√≥n del Aprendizaje del Modelo ARF (60 Minutos)')
    plt.xlabel('Minuto')
    plt.ylabel('Score')
    plt.legend()
    plt.grid(True, linestyle=':', alpha=0.6)
    plt.show()

# ==========================================
# PASO 7: MATRIZ, M√âTRICAS Y F√ìRMULAS
# ==========================================
print("\n" + "="*80)
print("üìä PASO 7: REPORTE FINAL Y AN√ÅLISIS MATEM√ÅTICO")
print("="*80)

LABELS_FIJAS = sorted(EMOCIONES_PERMITIDAS) # ["Enojo", "Felicidad", "Neutral", "Tristeza"]

if len(y_true_acumulado) > 0:
    # 1. Matriz de Confusi√≥n Visual
    cm = confusion_matrix(y_true_acumulado, y_pred_acumulado, labels=LABELS_FIJAS)

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=LABELS_FIJAS, yticklabels=LABELS_FIJAS)
    plt.title('Matriz de Confusi√≥n Final')
    plt.ylabel('Real')
    plt.xlabel('Predicho')
    plt.show()

    # 2. DEFINICI√ìN DE F√ìRMULAS
    print("\nüìê DEFINICI√ìN DE M√âTRICAS MATEM√ÅTICAS UTILIZADAS:")
    print("--------------------------------------------------")
    print("‚Ä¢ Accuracy (Exactitud):  (TP + TN) / (TP + TN + FP + FN)")
    print("  -> ¬øQu√© porcentaje de predicciones fueron correctas globalmente?")
    print("\n‚Ä¢ Precision (Precisi√≥n): TP / (TP + FP)")
    print("  -> De los que predije como 'Enojo', ¬øcu√°ntos eran realmente 'Enojo'?")
    print("\n‚Ä¢ Recall (Sensibilidad): TP / (TP + FN)")
    print("  -> De todos los 'Enojo' reales que exist√≠an, ¬øcu√°ntos detect√©?")
    print("--------------------------------------------------")

    # 3. Reporte de Clasificaci√≥n (Calculado por librer√≠a)
    print("\nüìã REPORTE DE CLASIFICACI√ìN (SKLEARN):")
    print(classification_report(y_true_acumulado, y_pred_acumulado, labels=LABELS_FIJAS, zero_division=0))

    # 4. AN√ÅLISIS MANUAL DE ERRORES (TP, TN, FP, FN)
    print("\nüîç DESGLOSE DETALLADO POR EMOCI√ìN (TP/TN/FP/FN):")
    total_muestras = len(y_true_acumulado)

    for i, label in enumerate(LABELS_FIJAS):
        # C√°lculos basados en la matriz de confusi√≥n 'cm'
        tp = cm[i, i]
        fp = cm[:, i].sum() - tp
        fn = cm[i, :].sum() - tp
        tn = total_muestras - (tp + fp + fn)

        # C√°lculo manual de m√©tricas para mostrar coherencia
        acc_manual = (tp + tn) / total_muestras if total_muestras > 0 else 0
        prec_manual = tp / (tp + fp) if (tp + fp) > 0 else 0
        rec_manual = tp / (tp + fn) if (tp + fn) > 0 else 0

        print(f"\n--- AN√ÅLISIS: {label.upper()} ---")
        print(f"   ‚úÖ Verdaderos Positivos (TP): {tp}  (Era {label} y predijo {label})")
        print(f"   üõ°Ô∏è Verdaderos Negativos (TN): {tn}  (NO era {label} y predijo otro)")
        print(f"   ‚ö†Ô∏è Falsos Positivos     (FP): {fp}  (Error Tipo I: Falsa alarma)")
        print(f"   ‚ùå Falsos Negativos     (FN): {fn}  (Error Tipo II: No detectado)")
        print(f"   -----------------------------------")
        print(f"   üßÆ Accuracy Local: {acc_manual:.2%} | Precision: {prec_manual:.2%} | Recall: {rec_manual:.2%}")

    # 5. Exportar a Excel
    try:
        df_export = pd.DataFrame({
            "Minuto": range(1, len(y_true_acumulado) + 1),
            "Real": y_true_acumulado,
            "Prediccion": y_pred_acumulado,
            "Acierto": [t == p for t, p in zip(y_true_acumulado, y_pred_acumulado)]
        })
        nombre_excel = "Reporte_Tesis_Completo.xlsx"
        df_export.to_excel(nombre_excel, index=False)
        print(f"\nüíæ EXCEL CREADO: '{nombre_excel}' guardado exitosamente.")
    except Exception as e:
        print(f"\n‚ö†Ô∏è No se pudo crear el Excel: {e}")

else:
    print("No se generaron predicciones para analizar.")